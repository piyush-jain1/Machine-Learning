library(ggplot2)
library(plyr)
library(stringr)
library(caret)
library(randomForest)
library(glmnet)
library(mice)
install.packages("gbm")
setwd("~/Desktop/Kaggle In Class")
#Load the files
train=read.csv("train2016.csv",na.strings = c("","NA"))
test=read.csv("test2016.csv",na.strings = c("","NA"))
summary(test)
clear
clear()
str(train)
levels(train$Gender)
levels(train$Q103293)
levels(train$Income)
summary(train)
#Basic Fixing of NA Values - Fixing Using Median/Most Frequent Observation
library(randomForest)
train=train[,c(1:6,8:108,7)]    #align (1-6):(1-6) & (8-108):(7-107)
data=rbind(train[,-108],test)
data=na.roughfix(data)
train=cbind(head(data,nrow(train)),Party=train[,108])
test=tail(data,nrow(test))
rm(data)
any(is.na(train))
any(is.na(test))
summary(train)
library(caret)
library(doParallel)
table(train$Party)
# repeatedcv = repeated k-folds
tctrl=trainControl(method="repeatedcv",
number=4,    # k
repeats=1,
classProbs = TRUE,
summaryFunction = defaultSummary,
allowParallel = TRUE    # makes it fast, for making 500 trees, it may run 5 parallel codes for 100 trees each
)
#Basic Modelling Using Logistic Regression
cl=makeCluster(6)
registerDoParallel(cl)
logregv1=train(Party~.,
data=train[-1],
method="glm",
trControl=tctrl
)
stopCluster(cl)
#Basic Modelling Using CART
cl=makeCluster(6)
registerDoParallel(cl)
cartv1=train(Party~.,       # '.' denotes all labels except party # Y ~ A + B + C + D
data=train[,-1],  #  removes first column
method="rpart",
trControl=tctrl
)
stopCluster(cl)
#Basic Modelling Using GBM
cl=makeCluster(4)
registerDoParallel(cl)
gbmv1=train(Party~.,
data=train[-1],
method="gbm",
trControl=tctrl
)
stopCluster(cl)
summary(train)
